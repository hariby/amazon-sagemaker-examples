{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker を使用した $K$-means クラスタリング\n",
    "\n",
    "- 次の AWS ブログの内容を元にしたノートブックです [[blog](https://aws.amazon.com/jp/blogs/news/k-means-clustering-with-amazon-sagemaker/)]\n",
    "- SageMaker ビルトインである $k$-means クラスタリングを実演\n",
    "- 実装のベースは [[Scully'10](https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf), [Mayerson'01](http://web.cs.ucla.edu/~awm/papers/ofl.pdf), [Guha et al.'03](https://papers.nips.cc/paper/4362-fast-and-accurate-k-means-for-large-datasets.pdf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import io\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "import sys\n",
    "import sagemaker.amazon.common as smac\n",
    "import os\n",
    "import mxnet as mx\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import urllib.request\n",
    "import gzip\n",
    "import pickle\n",
    "import sklearn.cluster\n",
    "import sklearn\n",
    "import re\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 バケットとプレフィックス\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-kmeans'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "def get_gdelt(filename):\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.Bucket('gdelt-open-data').download_file('events/' + filename, '.gdelt.csv')\n",
    "    df = pd.read_csv('.gdelt.csv', sep='\\t')\n",
    "    header = pd.read_csv('https://www.gdeltproject.org/data/lookups/CSV.header.historical.txt', sep='\\t')\n",
    "    df.columns = header.columns\n",
    "    return df\n",
    "\n",
    "data = get_gdelt('1979.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['EventCode', 'NumArticles', 'AvgTone', 'Actor1Geo_Lat', 'Actor1Geo_Long', 'Actor2Geo_Lat', 'Actor2Geo_Long']]\n",
    "data['EventCode'] = data['EventCode'].astype(object)\n",
    "\n",
    "events = pd.crosstab(index=data['EventCode'], columns='count').sort_values(by='count', ascending=False).index[:20]\n",
    "\n",
    "#トレーニングデータを Sagemaker K-means に必要な protobuf 形式に変換するルーチン\n",
    "def write_to_s3(bucket, prefix, channel, file_prefix, X):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_numpy_to_dense_tensor(buf, X.astype('float32'))\n",
    "    buf.seek(0)\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, channel, file_prefix + '.data')).upload_fileobj(buf)\n",
    "\n",
    "#上記のアクター場所とイベントに基づいて、データをフィルタリング\n",
    "def transform_gdelt(df, events=None):\n",
    "    df = df[['AvgTone', 'EventCode', 'NumArticles', 'Actor1Geo_Lat', 'Actor1Geo_Long', 'Actor2Geo_Lat', 'Actor2Geo_Long']]\n",
    "    df['EventCode'] = df['EventCode'].astype(object)\n",
    "    if events is not None:\n",
    "        df = df[np.in1d(df['EventCode'], events)]\n",
    "    return pd.get_dummies(df[((df['Actor1Geo_Lat'] == 0) & (df['Actor1Geo_Long'] == 0) != True) &\n",
    "                                   ((df['Actor2Geo_Lat'] == 0) & (df['Actor2Geo_Long'] == 0) != True)])\n",
    "\n",
    "#トレーニングを準備し、S3 に保存\n",
    "def prepare_gdelt(bucket, prefix, file_prefix, events=None, random_state=1729, save_to_s3=True):\n",
    "    df = get_gdelt(file_prefix + '.csv')\n",
    "    model_data = transform_gdelt(df, events)\n",
    "    train_data = model_data.sample(frac=1, random_state=random_state).as_matrix()\n",
    "    if save_to_s3:\n",
    "        write_to_s3(bucket, prefix, 'train', file_prefix, train_data)\n",
    "    return train_data\n",
    "\n",
    "# 1979 年用のデータセットを使用。\n",
    "train_79 = prepare_gdelt(bucket, prefix, '1979', events, save_to_s3=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1979 年のデータセットから最初の 10000 データポイントを可視化するために TSNE を使用\n",
    "from sklearn import manifold\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=1200)\n",
    "X_tsne = tsne.fit_transform(train_79[:10000])\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "X_tsne_1000 = X_tsne[:1000]\n",
    "plt.scatter(X_tsne_1000[:, 0], X_tsne_1000[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEGIN_YEAR = 1979\n",
    "END_YEAR = 1980\n",
    "\n",
    "for year in range(BEGIN_YEAR, END_YEAR):\n",
    "    train_data = prepare_gdelt(bucket, prefix, str(year), events)\n",
    "\n",
    "# SageMaker k-means ECR image ARN \n",
    "images = {'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/kmeans:latest',\n",
    "          'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/kmeans:latest',\n",
    "          'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/kmeans:latest',\n",
    "          'eu-west-1': '438346466558.dkr.ecr.eu-west-1.amazonaws.com/kmeans:latest'}\n",
    "image = images[boto3.Session().region_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "output_time = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "output_folder = 'kmeans-lowlevel-' + output_time\n",
    "K = range(2, 12) # k が使用する範囲を変更\n",
    "INSTANCE_COUNT = 2\n",
    "run_parallel_jobs = True #一度に 1 つのジョブを実行するには、これを false にします。\n",
    "#特に多数の EC2 インスタンスを 1 度に作成し、上限に達するのを避けたい場合\n",
    "job_names = []\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# すべての k でジョブを起動する\n",
    "for k in K:\n",
    "    print('starting train job:'+ str(k))\n",
    "    output_location = 's3://{}/kmeans_example/output/'.format(bucket) + output_folder\n",
    "    print('training artifacts will be uploaded to: {}'.format(output_location))\n",
    "    job_name = output_folder + str(k)\n",
    "\n",
    "    create_training_params = \\\n",
    "    {\n",
    "        \"AlgorithmSpecification\": {\n",
    "            \"TrainingImage\": image,\n",
    "            \"TrainingInputMode\": \"File\"\n",
    "        },\n",
    "        \"RoleArn\": role,\n",
    "        \"OutputDataConfig\": {\n",
    "            \"S3OutputPath\": output_location\n",
    "        },\n",
    "        \"ResourceConfig\": {\n",
    "            \"InstanceCount\": INSTANCE_COUNT,\n",
    "            \"InstanceType\": \"ml.c5.9xlarge\",\n",
    "            \"VolumeSizeInGB\": 50\n",
    "        },\n",
    "        \"TrainingJobName\": job_name,\n",
    "        \"HyperParameters\": {\n",
    "            \"k\": str(k),\n",
    "            \"feature_dim\": \"26\",\n",
    "            \"mini_batch_size\": \"1000\"\n",
    "        },\n",
    "        \"StoppingCondition\": {\n",
    "            \"MaxRuntimeInSeconds\": 60 * 60\n",
    "        },\n",
    "            \"InputDataConfig\": [\n",
    "            {\n",
    "                \"ChannelName\": \"train\",\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataType\": \"S3Prefix\",\n",
    "                        \"S3Uri\": \"s3://{}/{}/train/\".format(bucket, prefix),\n",
    "                        \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                    }\n",
    "                },\n",
    "\n",
    "                \"CompressionType\": \"None\",\n",
    "                \"RecordWrapperType\": \"None\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    sagemaker_client.create_training_job(**create_training_params)\n",
    "\n",
    "    status = sagemaker_client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "    print(status)\n",
    "    if not run_parallel_jobs:\n",
    "        try:\n",
    "            sagemaker_client.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "        finally:\n",
    "            status = sagemaker_client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "            print(\"Training job ended with status: \" + status)\n",
    "            if status == 'Failed':\n",
    "                message = sagemaker_client.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "                print('Training failed with the following error: {}'.format(message))\n",
    "                raise Exception('Training job failed')\n",
    "    \n",
    "    job_names.append(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(job_names):\n",
    "    try:\n",
    "        sagemaker_client.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_names[0])\n",
    "    finally:\n",
    "        status = sagemaker_client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "        print(\"Training job ended with status: \" + status)\n",
    "        if status == 'Failed':\n",
    "            message = sagemaker_client.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "            print('Training failed with the following error: {}'.format(message))\n",
    "            raise Exception('Training job failed')\n",
    "\n",
    "    print(job_name)\n",
    "\n",
    "    info = sagemaker_client.describe_training_job(TrainingJobName=job_name)\n",
    "    job_names.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()\n",
    "colors = ['b', 'g', 'r']\n",
    "markers = ['o', 'v', 's']\n",
    "models = {}\n",
    "distortions = []\n",
    "for k in K:\n",
    "    s3_client = boto3.client('s3')\n",
    "    key = 'kmeans_example/output/' + output_folder +'/' + output_folder + str(k) + '/output/model.tar.gz'\n",
    "    s3_client.download_file(bucket, key, 'model.tar.gz')\n",
    "    print(\"Model for k={} ({})\".format(k, key))\n",
    "    !tar -xvf model.tar.gz                       \n",
    "    kmeans_model=mx.ndarray.load('model_algo-1')\n",
    "    kmeans_numpy = kmeans_model[0].asnumpy()\n",
    "    distortions.append(sum(np.min(cdist(train_data, kmeans_numpy, 'euclidean'), axis=1)) / train_data.shape[0])\n",
    "    models[k] = kmeans_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エルボーをプロット\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('distortion')\n",
    "plt.title('Elbow graph')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
