{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker を使用した $K$-means クラスタリング\n",
    "\n",
    "- 次の AWS ブログの内容を元にしたノートブックです [[blog](https://aws.amazon.com/jp/blogs/news/k-means-clustering-with-amazon-sagemaker/)]\n",
    "- SageMaker ビルトインである $k$-means クラスタリングを実演\n",
    "- 実装のベースは [[Scully'10](https://www.eecs.tufts.edu/~dsculley/papers/fastkmeans.pdf), [Mayerson'01](http://web.cs.ucla.edu/~awm/papers/ofl.pdf), [Guha et al.'03](https://papers.nips.cc/paper/4362-fast-and-accurate-k-means-for-large-datasets.pdf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import io\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "import sys\n",
    "import sagemaker.amazon.common as smac\n",
    "import os\n",
    "import mxnet as mx\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import urllib.request\n",
    "import gzip\n",
    "import pickle\n",
    "import sklearn.cluster\n",
    "import sklearn\n",
    "import re\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 バケットとプレフィックス\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-kmeans'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "def get_gdelt(filename):\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.Bucket('gdelt-open-data').download_file('events/' + filename, '.gdelt.csv')\n",
    "    df = pd.read_csv('.gdelt.csv', sep='\\t')\n",
    "    header = pd.read_csv('https://www.gdeltproject.org/data/lookups/CSV.header.historical.txt', sep='\\t')\n",
    "    df.columns = header.columns\n",
    "    return df\n",
    "\n",
    "data = get_gdelt('1979.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['EventCode', 'NumArticles', 'AvgTone', 'Actor1Geo_Lat', 'Actor1Geo_Long', 'Actor2Geo_Lat', 'Actor2Geo_Long']]\n",
    "data['EventCode'] = data['EventCode'].astype(object)\n",
    "\n",
    "events = pd.crosstab(index=data['EventCode'], columns='count').sort_values(by='count', ascending=False).index[:20]\n",
    "\n",
    "#トレーニングデータを Sagemaker K-means に必要な protobuf 形式に変換するルーチン\n",
    "def write_to_s3(bucket, prefix, channel, file_prefix, X):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_numpy_to_dense_tensor(buf, X.astype('float32'))\n",
    "    buf.seek(0)\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, channel, file_prefix + '.data')).upload_fileobj(buf)\n",
    "\n",
    "#上記のアクター場所とイベントに基づいて、データをフィルタリング\n",
    "def transform_gdelt(df, events=None):\n",
    "    df = df[['AvgTone', 'EventCode', 'NumArticles', 'Actor1Geo_Lat', 'Actor1Geo_Long', 'Actor2Geo_Lat', 'Actor2Geo_Long']]\n",
    "    df['EventCode'] = df['EventCode'].astype(object)\n",
    "    if events is not None:\n",
    "        df = df[np.in1d(df['EventCode'], events)]\n",
    "    return pd.get_dummies(df[((df['Actor1Geo_Lat'] == 0) & (df['Actor1Geo_Long'] == 0) != True) &\n",
    "                                   ((df['Actor2Geo_Lat'] == 0) & (df['Actor2Geo_Long'] == 0) != True)])\n",
    "\n",
    "#トレーニングを準備し、S3 に保存\n",
    "def prepare_gdelt(bucket, prefix, file_prefix, events=None, random_state=1729, save_to_s3=True):\n",
    "    df = get_gdelt(file_prefix + '.csv')\n",
    "    model_data = transform_gdelt(df, events)\n",
    "    train_data = model_data.sample(frac=1, random_state=random_state).as_matrix()\n",
    "    if save_to_s3:\n",
    "        write_to_s3(bucket, prefix, 'train', file_prefix, train_data)\n",
    "    return train_data\n",
    "\n",
    "# 1979 年用のデータセットを使用。\n",
    "train_79 = prepare_gdelt(bucket, prefix, '1979', events, save_to_s3=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1979 年のデータセットから最初の 10000 データポイントを可視化するために TSNE を使用\n",
    "from sklearn import manifold\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=1200)\n",
    "X_tsne = tsne.fit_transform(train_79[:10000])\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "X_tsne_1000 = X_tsne[:1000]\n",
    "plt.scatter(X_tsne_1000[:, 0], X_tsne_1000[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEGIN_YEAR = 1979\n",
    "END_YEAR = 1980\n",
    "\n",
    "for year in range(BEGIN_YEAR, END_YEAR):\n",
    "    train_data = prepare_gdelt(bucket, prefix, str(year), events)\n",
    "\n",
    "# SageMaker k-means ECR image ARN \n",
    "images = {'us-west-2': '174872318107.dkr.ecr.us-west-2.amazonaws.com/kmeans:latest',\n",
    "          'us-east-1': '382416733822.dkr.ecr.us-east-1.amazonaws.com/kmeans:latest',\n",
    "          'us-east-2': '404615174143.dkr.ecr.us-east-2.amazonaws.com/kmeans:latest',\n",
    "          'eu-west-1': '438346466558.dkr.ecr.eu-west-1.amazonaws.com/kmeans:latest'}\n",
    "image = images[boto3.Session().region_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "output_time = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "output_folder = 'kmeans-lowlevel-' + output_time\n",
    "K = range(2, 12) # k が使用する範囲を変更\n",
    "INSTANCE_COUNT = 1\n",
    "run_parallel_jobs = True #一度に 1 つのジョブを実行するには、これを false にします。\n",
    "#特に多数の EC2 インスタンスを 1 度に作成し、上限に達するのを避けたい場合\n",
    "job_names = []\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# すべての k でジョブを起動する\n",
    "for k in K:\n",
    "    print('starting train job:'+ str(k))\n",
    "    output_location = 's3://{}/kmeans_example/output/'.format(bucket) + output_folder\n",
    "    print('training artifacts will be uploaded to: {}'.format(output_location))\n",
    "    job_name = output_folder + str(k)\n",
    "\n",
    "    create_training_params = \\\n",
    "    {\n",
    "        \"AlgorithmSpecification\": {\n",
    "            \"TrainingImage\": image,\n",
    "            \"TrainingInputMode\": \"File\"\n",
    "        },\n",
    "        \"RoleArn\": role,\n",
    "        \"OutputDataConfig\": {\n",
    "            \"S3OutputPath\": output_location\n",
    "        },\n",
    "        \"ResourceConfig\": {\n",
    "            \"InstanceCount\": INSTANCE_COUNT,\n",
    "            \"InstanceType\": \"ml.c5.18xlarge\",\n",
    "            \"VolumeSizeInGB\": 50\n",
    "        },\n",
    "        \"TrainingJobName\": job_name,\n",
    "        \"HyperParameters\": {\n",
    "            \"k\": str(k),\n",
    "            \"feature_dim\": \"26\",\n",
    "            \"mini_batch_size\": \"1000\"\n",
    "        },\n",
    "        \"StoppingCondition\": {\n",
    "            \"MaxRuntimeInSeconds\": 60 * 60\n",
    "        },\n",
    "            \"InputDataConfig\": [\n",
    "            {\n",
    "                \"ChannelName\": \"train\",\n",
    "                \"DataSource\": {\n",
    "                    \"S3DataSource\": {\n",
    "                        \"S3DataType\": \"S3Prefix\",\n",
    "                        \"S3Uri\": \"s3://{}/{}/train/\".format(bucket, prefix),\n",
    "                        \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                    }\n",
    "                },\n",
    "\n",
    "                \"CompressionType\": \"None\",\n",
    "                \"RecordWrapperType\": \"None\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    sagemaker_client.create_training_job(**create_training_params)\n",
    "\n",
    "    status = sagemaker_client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "    print(status)\n",
    "    if not run_parallel_jobs:\n",
    "        try:\n",
    "            sagemaker_client.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_name)\n",
    "        finally:\n",
    "            status = sagemaker_client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "            print(\"Training job ended with status: \" + status)\n",
    "            if status == 'Failed':\n",
    "                message = sagemaker_client.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "                print('Training failed with the following error: {}'.format(message))\n",
    "                raise Exception('Training job failed')\n",
    "    \n",
    "    job_names.append(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(job_names):\n",
    "    try:\n",
    "        sagemaker_client.get_waiter('training_job_completed_or_stopped').wait(TrainingJobName=job_names[0])\n",
    "    finally:\n",
    "        status = sagemaker_client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "        print(\"Training job ended with status: \" + status)\n",
    "        if status == 'Failed':\n",
    "            message = sagemaker_client.describe_training_job(TrainingJobName=job_name)['FailureReason']\n",
    "            print('Training failed with the following error: {}'.format(message))\n",
    "            raise Exception('Training job failed')\n",
    "\n",
    "    print(job_name)\n",
    "\n",
    "    info = sagemaker_client.describe_training_job(TrainingJobName=job_name)\n",
    "    job_names.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['b', 'g', 'r']\n",
    "markers = ['o', 'v', 's']\n",
    "models = {}\n",
    "distortions = []\n",
    "for k in K:\n",
    "    s3_client = boto3.client('s3')\n",
    "    key = 'kmeans_example/output/' + output_folder +'/' + output_folder + str(k) + '/output/model.tar.gz'\n",
    "    s3_client.download_file(bucket, key, 'model.tar.gz')\n",
    "    print(\"Model for k={} ({})\".format(k, key))\n",
    "    !tar -xvf model.tar.gz                       \n",
    "    kmeans_model=mx.ndarray.load('model_algo-1')\n",
    "    kmeans_numpy = kmeans_model[0].asnumpy()\n",
    "    distortions.append(sum(np.min(cdist(train_data, kmeans_numpy, 'euclidean'), axis=1)) / train_data.shape[0])\n",
    "    models[k] = kmeans_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エルボーをプロット\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('distortion')\n",
    "plt.title('Elbow graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hosting for the model\n",
    "以下では [[notebook](https://github.com/hariby/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/1P_kmeans_lowlevel/kmeans_mnist_lowlevel.ipynb)] を参考にして、推論用のエンドポイントを構築します。\n",
    "\n",
    "In order to set up hosting, we have to import the model from training to hosting. A common question would be, why wouldn't we automatically go from training to hosting?  And, in fact, the [k-means high-level example](/notebooks/sagemaker-python-sdk/1P_kmeans_highlevel/kmeans_mnist.ipynb) shows the functionality to do that.  For this low-level example though it makes sense to show each step in the process to provide a better understanding of the flexibility available.\n",
    "\n",
    "### Import model into hosting\n",
    "Next, you register the model with hosting. This allows you the flexibility of importing models trained elsewhere, as well as the choice of not importing models if the target of model creation is AWS Lambda, AWS Greengrass, Amazon Redshift, Amazon Athena, or other deployment target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_container = {\n",
    "    'Image': image,\n",
    "    'ModelDataUrl': info['ModelArtifacts']['S3ModelArtifacts']\n",
    "}\n",
    "\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = job_name, \n",
    "    ExecutionRoleArn = role, \n",
    "    PrimaryContainer = primary_container\n",
    ")\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint configuration\n",
    "Now, we'll create an endpoint configuration which provides the instance type and count for model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = 'KMeansEndpointConfig-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m4.xlarge',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':job_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "Lastly, the customer creates the endpoint that serves up the model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 9-11 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "endpoint_name = 'KMeansEndpoint-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "try:\n",
    "    sagemaker_client.get_waiter('endpoint_in_service').wait(EndpointName=endpoint_name)\n",
    "finally:\n",
    "    resp = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Arn: \" + resp['EndpointArn'])\n",
    "    print(\"Create endpoint ended with status: \" + status)\n",
    "\n",
    "    if status != 'InService':\n",
    "        message = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)['FailureReason']\n",
    "        print('Training failed with the following error: {}'.format(message))\n",
    "        raise Exception('Endpoint creation did not succeed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model for use\n",
    "Finally, we'll validate the model for use. Let's generate a classification for a single observation from the trained model using the endpoint we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function to create a csv from our numpy array\n",
    "def np2csv(arr):\n",
    "    csv = io.BytesIO()\n",
    "    np.savetxt(csv, arr, delimiter=',', fmt='%g')\n",
    "    return csv.getvalue().decode().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.Session().client('runtime.sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = np2csv(train_79[0:10000])\n",
    "\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='text/csv', \n",
    "                                   Body=payload)\n",
    "result = json.loads(response['Body'].read().decode())\n",
    "\n",
    "cluster_ids = np.array([int(result['predictions'][i]['closest_cluster']) for i in range(len(result['predictions']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "X_tsne_1000 = X_tsne[:1000]\n",
    "plt.scatter(X_tsne_1000[:, 0], X_tsne_1000[:, 1], c=cluster_ids[:1000])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
